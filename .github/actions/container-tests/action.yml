name: Container Tests
description: 'Run unit, integration, and smoke tests for all containers'
inputs:
  test-type:
    description: 'Type of tests to run: unit, integration, smoke, all'
    required: false
    default: 'all'
  fail-fast:
    description: 'Stop on first test failure'
    required: false
    default: 'false'
  upload-coverage:
    description: 'Upload test coverage reports'
    required: false
    default: 'true'

outputs:
  tests-passed:
    description: 'Whether all tests passed'
    value: ${{ steps.run-tests.outputs.passed }}
  coverage-percentage:
    description: 'Overall test coverage percentage'
    value: ${{ steps.coverage.outputs.percentage }}

runs:
  using: 'composite'
  steps:
    - name: Set up Python environment
      shell: bash
      run: |
        echo "🐍 Setting up Python test environment..."
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-asyncio pytest-xdist

    - name: Install container dependencies
      shell: bash
      run: |
        echo "📦 Installing container dependencies..."
        
        # Install each container's dependencies
        for container in content-collector content-processor content-ranker content-enricher content-generator site-generator markdown-generator collector-scheduler; do
          if [ -f "containers/$container/requirements.txt" ]; then
            echo "Installing dependencies for $container..."
            pip install -r containers/$container/requirements.txt
          else
            echo "No requirements.txt found for $container"
          fi
        done
        
        # Install shared libs
        if [ -f "libs/requirements.txt" ]; then
          echo "Installing shared libs dependencies..."
          pip install -r libs/requirements.txt
        fi
        
        # Install libs in editable mode
        pip install -e libs/

    - name: Run Unit Tests
      if: inputs.test-type == 'unit' || inputs.test-type == 'all'
      shell: bash
      run: |
        echo "🧪 Running unit tests across all containers..."
        
        pytest_args=""
        if [ "${{ inputs.fail-fast }}" = "true" ]; then
          pytest_args="$pytest_args -x"
        fi
        
        # Run unit tests with coverage
        python -m pytest \
          $pytest_args \
          -m unit \
          --cov=containers \
          --cov-report=xml:coverage-unit.xml \
          --cov-report=term-missing \
          --junit-xml=test-results-unit.xml \
          containers/
        
        echo "unit_exit_code=$?" >> $GITHUB_ENV

    - name: Run Integration Tests
      if: inputs.test-type == 'integration' || inputs.test-type == 'all'
      shell: bash
      run: |
        echo "🔗 Running integration tests across all containers..."
        
        pytest_args=""
        if [ "${{ inputs.fail-fast }}" = "true" ]; then
          pytest_args="$pytest_args -x"
        fi
        
        # Run integration tests
        python -m pytest \
          $pytest_args \
          -m integration \
          --cov=containers \
          --cov-append \
          --cov-report=xml:coverage-integration.xml \
          --cov-report=term-missing \
          --junit-xml=test-results-integration.xml \
          containers/
        
        echo "integration_exit_code=$?" >> $GITHUB_ENV

    - name: Run Smoke Tests
      if: inputs.test-type == 'smoke' || inputs.test-type == 'all'
      shell: bash
      run: |
        echo "💨 Running smoke tests (basic health checks)..."
        
        # Create smoke test runner
        cat > smoke_tests.py << 'EOF'
import subprocess
import sys
import os
from pathlib import Path

def run_smoke_test(container_name):
    """Run basic smoke test for a container."""
    container_path = Path(f"containers/{container_name}")
    
    if not container_path.exists():
        print(f"⚠️ Container {container_name} not found")
        return False
    
    print(f"🔍 Smoke testing {container_name}...")
    
    # Check if main.py exists and can be imported
    main_file = container_path / "main.py"
    if main_file.exists():
        try:
            # Add container to path and try import
            sys.path.insert(0, str(container_path))
            import importlib.util
            
            spec = importlib.util.spec_from_file_location("main", main_file)
            if spec and spec.loader:
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                print(f"✅ {container_name} main.py imports successfully")
                return True
            else:
                print(f"❌ {container_name} main.py failed to load")
                return False
        except Exception as e:
            print(f"❌ {container_name} import failed: {e}")
            return False
        finally:
            # Clean up path
            if str(container_path) in sys.path:
                sys.path.remove(str(container_path))
    else:
        print(f"⚠️ {container_name} has no main.py")
        return True  # Not all containers need main.py

containers = [
    "content-collector", "content-processor", "content-ranker", 
    "content-enricher", "content-generator", "site-generator", 
    "markdown-generator", "collector-scheduler"
]

failed_containers = []
for container in containers:
    if not run_smoke_test(container):
        failed_containers.append(container)

if failed_containers:
    print(f"❌ Smoke tests failed for: {', '.join(failed_containers)}")
    sys.exit(1)
else:
    print("✅ All smoke tests passed")
    sys.exit(0)
EOF

        python smoke_tests.py
        echo "smoke_exit_code=$?" >> $GITHUB_ENV

    - name: Run Performance Tests
      if: inputs.test-type == 'performance' || inputs.test-type == 'all'
      shell: bash
      run: |
        echo "⚡ Running performance tests..."
        
        pytest_args=""
        if [ "${{ inputs.fail-fast }}" = "true" ]; then
          pytest_args="$pytest_args -x"
        fi
        
        # Run performance tests (if any exist)
        python -m pytest \
          $pytest_args \
          -m performance \
          --junit-xml=test-results-performance.xml \
          containers/ || echo "No performance tests found"
        
        echo "performance_exit_code=$?" >> $GITHUB_ENV

    - name: Evaluate Test Results
      id: run-tests
      shell: bash
      run: |
        echo "📊 Evaluating test results..."
        
        overall_success=true
        
        # Check unit tests
        if [ "${{ inputs.test-type }}" = "unit" ] || [ "${{ inputs.test-type }}" = "all" ]; then
          if [ "${unit_exit_code:-0}" -ne 0 ]; then
            echo "❌ Unit tests failed"
            overall_success=false
          else
            echo "✅ Unit tests passed"
          fi
        fi
        
        # Check integration tests
        if [ "${{ inputs.test-type }}" = "integration" ] || [ "${{ inputs.test-type }}" = "all" ]; then
          if [ "${integration_exit_code:-0}" -ne 0 ]; then
            echo "❌ Integration tests failed"
            overall_success=false
          else
            echo "✅ Integration tests passed"
          fi
        fi
        
        # Check smoke tests
        if [ "${{ inputs.test-type }}" = "smoke" ] || [ "${{ inputs.test-type }}" = "all" ]; then
          if [ "${smoke_exit_code:-0}" -ne 0 ]; then
            echo "❌ Smoke tests failed"
            overall_success=false
          else
            echo "✅ Smoke tests passed"
          fi
        fi
        
        # Check performance tests
        if [ "${{ inputs.test-type }}" = "performance" ] || [ "${{ inputs.test-type }}" = "all" ]; then
          if [ "${performance_exit_code:-0}" -ne 0 ]; then
            echo "⚠️ Performance tests had issues (non-blocking)"
          else
            echo "✅ Performance tests passed"
          fi
        fi
        
        if [ "$overall_success" = "true" ]; then
          echo "✅ All container tests passed"
          echo "passed=true" >> $GITHUB_OUTPUT
        else
          echo "❌ Some container tests failed"
          echo "passed=false" >> $GITHUB_OUTPUT
          
          if [ "${{ inputs.fail-fast }}" = "true" ]; then
            exit 1
          fi
        fi

    - name: Generate Coverage Report
      id: coverage
      if: inputs.upload-coverage == 'true'
      shell: bash
      run: |
        echo "📈 Generating coverage report..."
        
        # Combine coverage reports if multiple exist
        if [ -f "coverage-unit.xml" ] && [ -f "coverage-integration.xml" ]; then
          python -m coverage combine
          python -m coverage xml -o coverage-combined.xml
          python -m coverage report --format=total > coverage-percentage.txt
        elif [ -f "coverage-unit.xml" ]; then
          cp coverage-unit.xml coverage-combined.xml
          python -m coverage report --format=total > coverage-percentage.txt
        fi
        
        # Extract coverage percentage
        if [ -f "coverage-percentage.txt" ]; then
          coverage_pct=$(cat coverage-percentage.txt | grep -o '[0-9]\+%' | head -1)
          echo "percentage=${coverage_pct:-0%}" >> $GITHUB_OUTPUT
          echo "📊 Overall test coverage: ${coverage_pct:-0%}"
        else
          echo "percentage=0%" >> $GITHUB_OUTPUT
        fi

    - name: Upload Test Results
      if: always()
      shell: bash
      run: |
        echo "📤 Test results summary:"
        
        # Create test summary
        cat > test-summary.md << EOF
# Container Test Results

## Test Execution Summary
- **Test Type**: ${{ inputs.test-type }}
- **Fail Fast**: ${{ inputs.fail-fast }}
- **Overall Result**: $([ "${{ steps.run-tests.outputs.passed }}" = "true" ] && echo "✅ PASSED" || echo "❌ FAILED")

## Coverage
- **Overall Coverage**: ${{ steps.coverage.outputs.percentage }}

## Test Categories
EOF

        # Add results for each test type
        if [ "${{ inputs.test-type }}" = "unit" ] || [ "${{ inputs.test-type }}" = "all" ]; then
          echo "- **Unit Tests**: $([ "${unit_exit_code:-0}" -eq 0 ] && echo "✅ PASSED" || echo "❌ FAILED")" >> test-summary.md
        fi
        
        if [ "${{ inputs.test-type }}" = "integration" ] || [ "${{ inputs.test-type }}" = "all" ]; then
          echo "- **Integration Tests**: $([ "${integration_exit_code:-0}" -eq 0 ] && echo "✅ PASSED" || echo "❌ FAILED")" >> test-summary.md
        fi
        
        if [ "${{ inputs.test-type }}" = "smoke" ] || [ "${{ inputs.test-type }}" = "all" ]; then
          echo "- **Smoke Tests**: $([ "${smoke_exit_code:-0}" -eq 0 ] && echo "✅ PASSED" || echo "❌ FAILED")" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        echo "Generated at: $(date -u)" >> test-summary.md
        
        cat test-summary.md
