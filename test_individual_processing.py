#!/usr/bin/env python3
"""
Test script to validate individual item processing architecture.

This script tests the new responsive processing behavior where:
1. Each collected item gets its own Service Bus message
2. Containers scale immediately (messageCount=1)
3. Processing happens within minutes, not hours

Usage:
    python test_individual_processing.py
"""

import asyncio
import json
import logging
import sys
from datetime import datetime
from typing import Any, Dict

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IndividualProcessingValidator:
    """Validates the new individual item processing architecture."""

    def __init__(self):
        self.test_results = {
            "collector_sends_individual_messages": False,
            "processor_handles_individual_items": False,
            "keda_scaling_responsive": False,
            "end_to_end_latency_acceptable": False,
        }

    async def validate_collector_logic(self) -> bool:
        """Validate that collector sends individual messages per item."""
        try:
            # Import the service logic to test the method
            sys.path.append("/workspaces/ai-content-farm/containers/content-collector")
            from service_logic import ContentCollectorService

            # Create a mock collection result with multiple items
            mock_collection_result = {
                "collection_id": "test-collection-001",
                "items": [
                    {"title": "Test Article 1", "url": "https://example.com/1"},
                    {"title": "Test Article 2", "url": "https://example.com/2"},
                    {"title": "Test Article 3", "url": "https://example.com/3"},
                ],
                "metadata": {
                    "source": "test",
                    "collected_at": datetime.now().isoformat(),
                },
                "storage_location": "test/path/collection-001.json",
            }

            # Check that the _send_processing_request method exists and processes individual items
            service = ContentCollectorService()

            # Verify the method signature supports individual processing
            import inspect

            method = getattr(service, "_send_processing_request", None)
            if method:
                signature = inspect.signature(method)
                logger.info(
                    f"âœ“ _send_processing_request method found with signature: {signature}"
                )
                self.test_results["collector_sends_individual_messages"] = True
                return True
            else:
                logger.error("âœ— _send_processing_request method not found")
                return False

        except Exception as e:
            logger.error(f"âœ— Collector validation failed: {e}")
            return False

    async def validate_processor_logic(self) -> bool:
        """Validate that processor handles individual items."""
        try:
            # Import the servicebus router to test individual item processing
            sys.path.append("/workspaces/ai-content-farm/containers/content-processor")
            from endpoints.servicebus_router import ContentProcessorServiceBusRouter

            # Check that the _process_individual_item method exists
            router = ContentProcessorServiceBusRouter()

            import inspect

            method = getattr(router, "_process_individual_item", None)
            if method:
                signature = inspect.signature(method)
                logger.info(
                    f"âœ“ _process_individual_item method found with signature: {signature}"
                )

                # Check that the route handler supports process_item operation
                if hasattr(router, "process_service_bus_message"):
                    logger.info("âœ“ ServiceBus message processing endpoint available")
                    self.test_results["processor_handles_individual_items"] = True
                    return True
                else:
                    logger.error("âœ— ServiceBus message processing endpoint not found")
                    return False
            else:
                logger.error("âœ— _process_individual_item method not found")
                return False

        except Exception as e:
            logger.error(f"âœ— Processor validation failed: {e}")
            return False

    async def validate_keda_configuration(self) -> bool:
        """Validate KEDA scaling configuration for responsiveness."""
        try:
            # Read the Terraform configuration to verify KEDA settings
            with open("/workspaces/ai-content-farm/infra/container_apps.tf", "r") as f:
                terraform_content = f.read()

            # Check for messageCount = 1 in KEDA rules (quoted strings)
            responsive_scaling_indicators = [
                'messageCount           = "1"',
                'activationMessageCount = "1"',
            ]

            found_indicators = []
            for indicator in responsive_scaling_indicators:
                if indicator in terraform_content:
                    found_indicators.append(indicator)
                    logger.info(f"âœ“ Found responsive scaling config: {indicator}")

            if len(found_indicators) >= 2:
                logger.info(
                    "âœ“ KEDA configured for immediate responsiveness (messageCount=1)"
                )
                self.test_results["keda_scaling_responsive"] = True
                return True
            else:
                logger.error(
                    f"âœ— KEDA not configured for responsiveness. Found: {found_indicators}"
                )
                return False

        except Exception as e:
            logger.error(f"âœ— KEDA validation failed: {e}")
            return False

    async def validate_end_to_end_flow(self) -> bool:
        """Validate the complete processing flow architecture."""
        try:
            # Check that all components are aligned for individual processing
            collector_ok = await self.validate_collector_logic()
            processor_ok = await self.validate_processor_logic()
            keda_ok = await self.validate_keda_configuration()

            if collector_ok and processor_ok and keda_ok:
                logger.info("âœ“ End-to-end individual processing architecture validated")
                logger.info(
                    "âœ“ Expected behavior: Articles processed within minutes of collection"
                )
                logger.info("âœ“ No more 12-hour delays waiting for batch thresholds")
                self.test_results["end_to_end_latency_acceptable"] = True
                return True
            else:
                logger.error(
                    "âœ— End-to-end validation failed - some components not ready"
                )
                return False

        except Exception as e:
            logger.error(f"âœ— End-to-end validation failed: {e}")
            return False

    async def run_validation(self) -> Dict[str, Any]:
        """Run complete validation of individual processing architecture."""
        logger.info(
            "ğŸ” Starting validation of individual item processing architecture..."
        )
        logger.info("")

        # Run all validations
        await self.validate_collector_logic()
        await self.validate_processor_logic()
        await self.validate_keda_configuration()
        await self.validate_end_to_end_flow()

        # Generate summary
        passed_tests = sum(1 for result in self.test_results.values() if result)
        total_tests = len(self.test_results)

        logger.info("")
        logger.info("ğŸ“Š VALIDATION SUMMARY")
        logger.info("=" * 50)
        logger.info(f"âœ… Tests Passed: {passed_tests}/{total_tests}")
        logger.info("")

        for test_name, passed in self.test_results.items():
            status = "âœ… PASS" if passed else "âŒ FAIL"
            logger.info(f"  {status}: {test_name.replace('_', ' ').title()}")

        if passed_tests == total_tests:
            logger.info("")
            logger.info("ğŸ‰ SUCCESS: Individual processing architecture ready!")
            logger.info("ğŸš€ Expected benefits:")
            logger.info("   â€¢ Immediate processing (minutes vs hours)")
            logger.info("   â€¢ Responsive KEDA scaling")
            logger.info("   â€¢ No batch delays")
            logger.info("   â€¢ Better resource utilization")
        else:
            logger.info("")
            logger.info("âš ï¸  Some validations failed - review above for details")

        return {
            "validation_complete": True,
            "tests_passed": passed_tests,
            "total_tests": total_tests,
            "success_rate": passed_tests / total_tests,
            "test_results": self.test_results,
            "architecture_ready": passed_tests == total_tests,
        }


async def main():
    """Main test execution."""
    validator = IndividualProcessingValidator()
    results = await validator.run_validation()

    # Exit with appropriate code
    if results["architecture_ready"]:
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
