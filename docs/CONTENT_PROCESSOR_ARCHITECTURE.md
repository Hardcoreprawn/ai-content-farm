 # Content Processor Container: Architecture & Blob Reading Flow

## Overview

The Content Processor is a FastAPI-based container that processes collected content through AI enhancement. It's designed around an event-driven "wake-up work queue" pattern where external triggers (KEDA/HTTP) signal work availability.

## Container Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CONTENT PROCESSOR CONTAINER                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“¡ TRIGGERS                                                    â”‚
â”‚  â”œâ”€ KEDA (Azure Container Apps)                                â”‚
â”‚  â”œâ”€ HTTP POST /process/wake-up                                â”‚
â”‚  â””â”€ Manual API calls                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸŒ FASTAPI APPLICATION (main.py)                             â”‚
â”‚  â”œâ”€ CORS middleware                                           â”‚
â”‚  â”œâ”€ Request validation                                        â”‚
â”‚  â”œâ”€ Error handling                                            â”‚
â”‚  â””â”€ Lifecycle management                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¯ ENDPOINT LAYER (endpoints.py)                             â”‚
â”‚  â”œâ”€ wake_up_endpoint()                                        â”‚
â”‚  â”œâ”€ process_batch_endpoint()                                  â”‚
â”‚  â”œâ”€ health_endpoint()                                         â”‚
â”‚  â””â”€ status_endpoint()                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ§  PROCESSOR CORE (processor.py)                             â”‚
â”‚  â”œâ”€ ContentProcessor class                                    â”‚
â”‚  â”œâ”€ Session tracking                                          â”‚
â”‚  â”œâ”€ Health monitoring                                         â”‚
â”‚  â””â”€ Service coordination                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” SERVICE LAYER                                             â”‚
â”‚  â”œâ”€ TopicDiscoveryService   â†’ Blob reading & filtering       â”‚
â”‚  â”œâ”€ ArticleGenerationService â†’ AI content creation           â”‚
â”‚  â”œâ”€ LeaseCoordinator        â†’ Distributed locking            â”‚
â”‚  â””â”€ ProcessorStorageService â†’ Result persistence             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¾ INFRASTRUCTURE LAYER                                      â”‚
â”‚  â”œâ”€ SimplifiedBlobClient    â†’ Azure Storage operations       â”‚
â”‚  â”œâ”€ BlobAuthManager         â†’ Authentication & connection    â”‚
â”‚  â”œâ”€ AsyncAzureOpenAI        â†’ AI model interaction           â”‚
â”‚  â””â”€ ContractValidator       â†’ Data validation                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Complete Wake-up to Blob Reading Flow

### 1. Trigger Reception
```
HTTP POST /process/wake-up
{
  "source": "collector",
  "batch_size": 10,
  "priority_threshold": 0.5,
  "debug_bypass": false
}
```

**Components Involved:**
- `main.py` â†’ FastAPI request handling
- `endpoints.py:wake_up_endpoint()` â†’ Request parsing

### 2. Processor Initialization
```python
# endpoints.py:wake_up_endpoint()
processor = get_processor()  # Singleton ContentProcessor instance
result = await processor.process_available_work(
    batch_size=request.batch_size,
    priority_threshold=request.priority_threshold,
    debug_bypass=request.debug_bypass
)
```

**Components Involved:**
- `processor.py:ContentProcessor.__init__()` â†’ Service initialization
- Creates `TopicDiscoveryService` with `SimplifiedBlobClient`

### 3. Topic Discovery Phase
```python
# processor.py:process_available_work()
available_topics = await self.topic_discovery.find_available_topics(
    batch_size, priority_threshold, debug_bypass=debug_bypass
)
```

**Components Involved:**
- `services/topic_discovery.py:find_available_topics()`

### 4. Blob Storage Connection
```python
# libs/simplified_blob_client.py:__init__()
self.auth_manager = BlobAuthManager()
self.blob_service_client = self.auth_manager.get_blob_service_client()
```

**Authentication Flow:**
```
libs/blob_auth.py:BlobAuthManager.get_blob_service_client()
â”œâ”€ Check AZURE_STORAGE_CONNECTION_STRING (if available)
â”œâ”€ Fallback to AZURE_STORAGE_ACCOUNT_NAME + Managed Identity
â”‚  â”œâ”€ Production: ManagedIdentityCredential(client_id)
â”‚  â”œâ”€ Development: DefaultAzureCredential
â”‚  â””â”€ Account URL: https://{account_name}.blob.core.windows.net
â””â”€ Return BlobServiceClient instance
```

### 5. Blob Discovery
```python
# topic_discovery.py:find_available_topics()
blobs = await self.blob_client.list_blobs("collected-content")
```

**Blob Listing Process:**
```
libs/simplified_blob_client.py:list_blobs()
â”œâ”€ Get container client: blob_service_client.get_container_client("collected-content")
â”œâ”€ Enumerate blobs: container_client.list_blobs(name_starts_with=prefix)
â”œâ”€ Extract metadata: {name, size, last_modified, content_type}
â””â”€ Return List[Dict[str, Any]]
```

### 6. Blob Content Download
```python
# topic_discovery.py (for each blob)
collection_data = await self.blob_client.download_json(
    "collected-content", blob_name
)
```

**Download Process:**
```
libs/simplified_blob_client.py:download_json()
â”œâ”€ Get blob client: blob_service_client.get_blob_client(container, blob_name)
â”œâ”€ Download content: blob_client.download_blob().readall()
â”œâ”€ Parse JSON: json.loads(content.decode())
â””â”€ Return Dict[str, Any]
```

### 7. Data Validation & Filtering
```python
# topic_discovery.py
if not debug_bypass and not self._is_valid_collection(collection_data):
    continue  # Skip invalid collections

# Process items
for item_data in collection_data.get("items", []):
    if debug_bypass:
        topic = self._raw_item_to_topic_metadata(item_data, blob_name)
    else:
        validated_item = ContractValidator.validate_collection_item(item_data)
        topic = self._validated_item_to_topic_metadata(validated_item, blob_name)
```

## Why Blob Reading Might Fail

### Common Failure Points

1. **Authentication Issues**
   - Missing `AZURE_STORAGE_ACCOUNT_NAME` environment variable
   - Managed Identity not properly configured
   - Network connectivity to Azure Storage

2. **Container Access**
   - Container `collected-content` doesn't exist
   - Insufficient permissions (Reader role needed)
   - Firewall/network rules blocking access

3. **Data Format Issues**
   - Blob content isn't valid JSON
   - Missing required fields in collections
   - Encoding issues (non-UTF8 content)

4. **Memory/Performance**
   - Large blobs causing timeout
   - Too many blobs overwhelming the container
   - Rate limiting from Azure Storage

### Debug Commands

```bash
# Test blob storage connectivity
curl -X GET "https://ai-content-prod-processor.../processing/diagnostics"

# Test with debug bypass (skips all validation)
curl -X POST "https://ai-content-prod-processor.../process/wake-up" \
  -H "Content-Type: application/json" \
  -d '{"source": "debug", "debug_bypass": true, "batch_size": 1}'

# Check container health
curl -X GET "https://ai-content-prod-processor.../health"
```

## Environment Variables Required

```bash
# Primary authentication (choose one)
AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=..."
# OR
AZURE_STORAGE_ACCOUNT_NAME="aicontentprodstkwakpx"
AZURE_CLIENT_ID="..."  # For managed identity

# Optional
ENVIRONMENT="production"  # affects auth method selection
```

## Container Resource Flow

```
User/KEDA â†’ HTTP Request â†’ FastAPI â†’ Endpoint â†’ Processor â†’ TopicDiscovery
    â†“
SimplifiedBlobClient â†’ BlobAuthManager â†’ Azure Storage API
    â†“
JSON Collections â†’ Data Validation â†’ TopicMetadata Objects
    â†“
AI Processing â†’ Article Generation â†’ Storage â†’ Response
```

The blob reading process involves 6 distinct layers, each with potential failure points. The debug bypass functionality allows us to skip validation layers and identify exactly where the pipeline breaks.